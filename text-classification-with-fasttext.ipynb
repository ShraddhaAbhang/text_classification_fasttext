{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-09-03T10:09:31.685420Z","iopub.status.busy":"2021-09-03T10:09:31.684947Z","iopub.status.idle":"2021-09-03T10:09:31.697713Z","shell.execute_reply":"2021-09-03T10:09:31.696771Z","shell.execute_reply.started":"2021-09-03T10:09:31.685290Z"},"id":"YKgZXvTGb61z","trusted":true},"outputs":[],"source":["#necessary imports\n","import os\n","import pandas as pd"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-09-03T10:09:31.699717Z","iopub.status.busy":"2021-09-03T10:09:31.699260Z","iopub.status.idle":"2021-09-03T10:09:37.725523Z","shell.execute_reply":"2021-09-03T10:09:37.724192Z","shell.execute_reply.started":"2021-09-03T10:09:31.699686Z"},"executionInfo":{"elapsed":2574,"status":"ok","timestamp":1630380801754,"user":{"displayName":"洪培翊","photoUrl":"","userId":"05781060770242921264"},"user_tz":-480},"id":"lMoRw3oQb62I","outputId":"343c1b68-1767-4e15-a2ed-7f1118e37ca5","trusted":true},"outputs":[{"ename":"UnicodeDecodeError","evalue":"'utf-8' codec can't decode byte 0xa4 in position 14: invalid start byte","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Loading test data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m test_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput/test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m df_test \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Data we have\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Test:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(df\u001b[38;5;241m.\u001b[39mshape,df_test\u001b[38;5;241m.\u001b[39mshape))\n","File \u001b[1;32mc:\\Users\\Shraddha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Shraddha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[1;32mc:\\Users\\Shraddha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Shraddha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\Shraddha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Shraddha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:548\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mc:\\Users\\Shraddha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:740\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mc:\\Users\\Shraddha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:848\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mc:\\Users\\Shraddha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mc:\\Users\\Shraddha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:2017\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n","\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa4 in position 14: invalid start byte"]}],"source":["# Loading train data\n","train_file = \"input/train.csv\"\n","df = pd.read_csv(train_file, header=None, names=['class','name','description'])\n","# Loading test data\n","test_file = \"input/test.csv\"\n","df_test = pd.read_csv(test_file, header=None, names=['class','name','description'])\n","# Data we have\n","print(\"Train:{} Test:{}\".format(df.shape,df_test.shape))"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-09-03T10:09:37.728491Z","iopub.status.busy":"2021-09-03T10:09:37.728015Z","iopub.status.idle":"2021-09-03T10:09:37.758539Z","shell.execute_reply":"2021-09-03T10:09:37.757495Z","shell.execute_reply.started":"2021-09-03T10:09:37.728441Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1630380817113,"user":{"displayName":"洪培翊","photoUrl":"","userId":"05781060770242921264"},"user_tz":-480},"id":"I9TxpEcdRNv0","outputId":"6e9da9bd-b575-4b38-db3e-72c3f322e2f6","trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n","\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-09-03T10:09:37.760286Z","iopub.status.busy":"2021-09-03T10:09:37.759984Z","iopub.status.idle":"2021-09-03T10:09:37.773257Z","shell.execute_reply":"2021-09-03T10:09:37.771903Z","shell.execute_reply.started":"2021-09-03T10:09:37.760257Z"},"executionInfo":{"elapsed":841,"status":"ok","timestamp":1630380836152,"user":{"displayName":"洪培翊","photoUrl":"","userId":"05781060770242921264"},"user_tz":-480},"id":"zgA1dnPARRtS","outputId":"37cd6d2e-125d-4e70-95a2-44d6b0e3cb55","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>name</th>\n","      <th>description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>TY KU</td>\n","      <td>TY KU /taɪkuː/ is an American alcoholic bever...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Odd Lot Entertainment</td>\n","      <td>OddLot Entertainment founded in 2001 by longt...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Henkel</td>\n","      <td>Henkel AG &amp; Company KGaA operates worldwide w...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>GOAT Store</td>\n","      <td>The GOAT Store (Games Of All Type Store) LLC ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>RagWing Aircraft Designs</td>\n","      <td>RagWing Aircraft Designs (also called the Rag...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class                      name   \n","0      1                     TY KU  \\\n","1      1     Odd Lot Entertainment   \n","2      1                    Henkel   \n","3      1                GOAT Store   \n","4      1  RagWing Aircraft Designs   \n","\n","                                         description  \n","0   TY KU /taɪkuː/ is an American alcoholic bever...  \n","1   OddLot Entertainment founded in 2001 by longt...  \n","2   Henkel AG & Company KGaA operates worldwide w...  \n","3   The GOAT Store (Games Of All Type Store) LLC ...  \n","4   RagWing Aircraft Designs (also called the Rag...  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_test.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-09-03T10:09:37.775156Z","iopub.status.busy":"2021-09-03T10:09:37.774838Z","iopub.status.idle":"2021-09-03T10:09:37.821138Z","shell.execute_reply":"2021-09-03T10:09:37.820135Z","shell.execute_reply.started":"2021-09-03T10:09:37.775126Z"},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1630380963949,"user":{"displayName":"洪培翊","photoUrl":"","userId":"05781060770242921264"},"user_tz":-480},"id":"gaz226vXb62W","outputId":"3e30ace4-7708-4653-f13c-aa984bc2b7cc","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>name</th>\n","      <th>description</th>\n","      <th>class_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>E. D. Abbott Ltd</td>\n","      <td>Abbott of Farnham E D Abbott Limited was a Br...</td>\n","      <td>Company</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Schwan-Stabilo</td>\n","      <td>Schwan-STABILO is a German maker of pens for ...</td>\n","      <td>Company</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Q-workshop</td>\n","      <td>Q-workshop is a Polish company located in Poz...</td>\n","      <td>Company</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>Marvell Software Solutions Israel</td>\n","      <td>Marvell Software Solutions Israel known as RA...</td>\n","      <td>Company</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>Bergan Mercy Medical Center</td>\n","      <td>Bergan Mercy Medical Center is a hospital loc...</td>\n","      <td>Company</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class                               name   \n","0      1                   E. D. Abbott Ltd  \\\n","1      1                     Schwan-Stabilo   \n","2      1                         Q-workshop   \n","3      1  Marvell Software Solutions Israel   \n","4      1        Bergan Mercy Medical Center   \n","\n","                                         description class_name  \n","0   Abbott of Farnham E D Abbott Limited was a Br...    Company  \n","1   Schwan-STABILO is a German maker of pens for ...    Company  \n","2   Q-workshop is a Polish company located in Poz...    Company  \n","3   Marvell Software Solutions Israel known as RA...    Company  \n","4   Bergan Mercy Medical Center is a hospital loc...    Company  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Since we have no clue about the classes lets build one\n","# Mapping from class number to class name\n","class_dict={\n","            1:'Company',\n","            2:'EducationalInstitution',\n","            3:'Artist',\n","            4:'Athlete',\n","            5:'OfficeHolder',\n","            6:'MeanOfTransportation',\n","            7:'Building',\n","            8:'NaturalPlace',\n","            9:'Village',\n","            10:'Animal',\n","            11:'Plant',\n","            12:'Album',\n","            13:'Film',\n","            14:'WrittenWork'\n","        }\n","\n","# Mapping the classes\n","df['class_name'] = df['class'].map(class_dict)\n","df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-09-03T10:09:37.822897Z","iopub.status.busy":"2021-09-03T10:09:37.822571Z","iopub.status.idle":"2021-09-03T10:09:37.954829Z","shell.execute_reply":"2021-09-03T10:09:37.953682Z","shell.execute_reply.started":"2021-09-03T10:09:37.822864Z"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1630380974617,"user":{"displayName":"洪培翊","photoUrl":"","userId":"05781060770242921264"},"user_tz":-480},"id":"si7VC_Rub62a","outputId":"5d377160-927b-4d9e-b272-8f0dcef7ba27","trusted":true},"outputs":[{"data":{"text/plain":["class_name\n","Company                   40000\n","EducationalInstitution    40000\n","Artist                    40000\n","Athlete                   40000\n","OfficeHolder              40000\n","MeanOfTransportation      40000\n","Building                  40000\n","NaturalPlace              40000\n","Village                   40000\n","Animal                    40000\n","Plant                     40000\n","Album                     40000\n","Film                      40000\n","WrittenWork               40000\n","Name: count, dtype: int64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df[\"class_name\"].value_counts()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-09-03T10:09:37.956689Z","iopub.status.busy":"2021-09-03T10:09:37.956334Z","iopub.status.idle":"2021-09-03T10:09:37.967344Z","shell.execute_reply":"2021-09-03T10:09:37.966348Z","shell.execute_reply.started":"2021-09-03T10:09:37.956659Z"},"id":"Sn-3kIqMb62d","trusted":true},"outputs":[],"source":["# Lets do some cleaning of this text\n","def clean_it(text,normalize=True):\n","    # Replacing possible issues with data. We can add or reduce the replacemtent in this chain\n","    s = str(text).replace(',',' ').replace('\"','').replace('\\'',' \\' ').replace('.',' . ').replace('(',' ( ').\\\n","            replace(')',' ) ').replace('!',' ! ').replace('?',' ? ').replace(':',' ').replace(';',' ').lower()\n","    \n","    # normalizing / encoding the text\n","    if normalize:\n","        s = s.normalize('NFKD').str.encode('ascii','ignore').str.decode('utf-8')\n","    \n","    return s\n","\n","# Now lets define a small function where we can use above cleaning on datasets\n","def clean_df(data, cleanit= False, shuffleit=False, encodeit=False, label_prefix='__class__'):\n","    # Defining the new data\n","    df = data[['name','description']].copy(deep=True)\n","    df['class'] = label_prefix + data['class'].astype(str) + ' '\n","    \n","    # cleaning it\n","    if cleanit:\n","        df['name'] = df['name'].apply(lambda x: clean_it(x,encodeit))\n","        df['description'] = df['description'].apply(lambda x: clean_it(x,encodeit))\n","    \n","    # shuffling it\n","    if shuffleit:\n","        df.sample(frac=1).reset_index(drop=True)\n","            \n","    return df"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-09-03T10:09:37.969946Z","iopub.status.busy":"2021-09-03T10:09:37.969409Z","iopub.status.idle":"2021-09-03T10:09:44.224872Z","shell.execute_reply":"2021-09-03T10:09:44.223720Z","shell.execute_reply.started":"2021-09-03T10:09:37.969898Z"},"executionInfo":{"elapsed":5744,"status":"ok","timestamp":1630380999596,"user":{"displayName":"洪培翊","photoUrl":"","userId":"05781060770242921264"},"user_tz":-480},"id":"r_DRvdFcb62m","outputId":"03057a3f-05ab-4ec2-8e5c-bd2ccde01771","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 5.22 s\n","Wall time: 5.86 s\n"]}],"source":["%%time\n","# Transform the datasets using the above clean functions\n","df_train_cleaned = clean_df(df, True, True)\n","df_test_cleaned = clean_df(df_test, True, True)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-09-03T10:09:44.226480Z","iopub.status.busy":"2021-09-03T10:09:44.226136Z","iopub.status.idle":"2021-09-03T10:09:54.396197Z","shell.execute_reply":"2021-09-03T10:09:54.394989Z","shell.execute_reply.started":"2021-09-03T10:09:44.226445Z"},"id":"imMZ9-Bkb62t","trusted":true},"outputs":[],"source":["# Write files to disk as fastText classifier API reads files from disk.\n","train_file =  'final_train.csv'\n","df_train_cleaned.to_csv(train_file, header=None, index=False, columns=['class','name','description'] )\n","\n","test_file = 'final_test.csv'\n","df_test_cleaned.to_csv(test_file, header=None, index=False, columns=['class','name','description'] )\n"]},{"cell_type":"markdown","metadata":{"id":"bWZTSzd9b62x"},"source":["Now that we have the train and test files written into disk in a format fastText wants, we are ready to use it for text classification!"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting fasttext\n","  Downloading fasttext-0.9.2.tar.gz (68 kB)\n","Collecting pybind11>=2.2\n","  Using cached pybind11-2.12.0-py3-none-any.whl (234 kB)\n","Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\shraddha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fasttext) (57.4.0)\n","Requirement already satisfied: numpy in c:\\users\\shraddha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fasttext) (1.24.3)\n","Using legacy 'setup.py install' for fasttext, since package 'wheel' is not installed.\n","Installing collected packages: pybind11, fasttext\n","    Running setup.py install for fasttext: started\n","    Running setup.py install for fasttext: finished with status 'done'\n","Successfully installed fasttext-0.9.2 pybind11-2.12.0\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n","You should consider upgrading via the 'C:\\Users\\Shraddha\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"]}],"source":["!pip install fasttext"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-09-03T10:09:54.398332Z","iopub.status.busy":"2021-09-03T10:09:54.397801Z"},"id":"a-H1wouCb62x","trusted":true},"outputs":[],"source":["from fasttext import train_supervised \n","\"\"\"fastText expects and training file (csv), a model name as input arguments.\n","label_prefix refers to the prefix before label string in the dataset.\n","default is __label__. In our dataset, it is __class__. \n","There are several other parameters which can be seen in: \n","https://pypi.org/project/fasttext/\n","\"\"\"\n","model = train_supervised(input=train_file, label=\"__class__\", lr=1.0, epoch=5, loss='ova', wordNgrams=2, dim=200, verbose=100)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"sAyN3ZDbQFq-","outputId":"13acbc62-48d9-469c-dfb1-d3e5446b8530","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Samples: 70000 Precision@1 : 35.9200 Recall@1 : 35.9200\n","Test Samples: 70000 Precision@2 : 29.7114 Recall@2 : 59.4229\n","Test Samples: 70000 Precision@3 : 24.0090 Recall@3 : 72.0271\n","Test Samples: 70000 Precision@4 : 19.0621 Recall@4 : 76.2486\n","Test Samples: 70000 Precision@5 : 16.5589 Recall@5 : 82.7943\n"]}],"source":["for k in range(1,6):\n","    results = model.test(test_file,k=k)\n","    print(f\"Test Samples: {results[0]} Precision@{k} : {results[1]*100:2.4f} Recall@{k} : {results[2]*100:2.4f}\")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["text = \" l ' indépendant is a newspaper published in luxembourg from 1945 .\"\n","prediction = model.predict(text)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(('__class__14',), array([1.00001001]))\n"]}],"source":["print(prediction)"]},{"cell_type":"markdown","metadata":{"id":"nrxSYRs3b621"},"source":["Try training a classifier on this dataset with, say, LogisticRegression to realize how fast fastText is! 93% Precision and Recall are hard numbers to beat, too!"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
